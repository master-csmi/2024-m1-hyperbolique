\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{float}

\usepackage{listings}
\usepackage{xcolor}
\lstset{ % General setup for the package
    language=Python,
    basicstyle=\small\sffamily,
    numbers=left,
    numberstyle=\tiny,
    frame=single,
    tabsize=4,
    columns=fixed,
    showtabs=false,
    keepspaces,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{gray},
    stringstyle=\color{orange},
    showstringspaces=false,
    breaklines=true,
    tabsize=4,
    escapeinside={*@}{@*},
    xleftmargin=14mm,
    xrightmargin=14mm,
}

\addtolength{\oddsidemargin}{-.75in}%
\addtolength{\evensidemargin}{-.75in}%
\addtolength{\textwidth}{1.7in}%
\addtolength{\textheight}{1.5in}%
\addtolength{\topmargin}{-.8in}%


\begin{document}
\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

\title{\bf M1 CSMI Project\\ Adaptive Implicit Schemes for Hyperbolic Equations}
\author{Antoine REGARDIN\hspace{.2cm}\\
    Supervisors: Emmanuel FRANCK, Andrea THOMANN\\
    University of Strasbourg\\ }
\date{Spring 2024}
\maketitle

\tableofcontents

\newpage

\section{Introduction: Context}
In the numerical analysis of hyperbolic problems, explicit schemes present very bad results, and solutions obtained with implicit schemes
are too prone to dissipation. This is why Theta Schemes (including the Crank-Nicholson scheme) are an interesting compromise for their study.\\
Another issue comes to us when studying more specific problems, with discontinuous initial solutions $u_{t=0}(x)$: when using a normal theta scheme (with any $\theta$ between 0 and 1),
the numerical solution does not behave well around such discontinuities. A possible solution to this could be to make $\theta$ vary in function of each space and time cells of our mesh.\\
Indeed, representing a discontinuity in space is achievable without issues, but implementing a solver in time is another problem.
Here, as our discontinuity is moving in function of the time, "a shock in space is also a shock in time".\\
\vspace{10pt}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.3\textwidth]{u0-example.png}
    \caption{An example of an initial function presenting a discontinuous jump.}
\end{figure}

It is important to find a solution to this issue, as local discontinuities -or singularities- can be important in modelling in fluids, materials or waveforms Physics.
For example, many phenomena can be studied at the boundary between two different physical media,
with corresponding functions presenting a jump in space.\\
To sum up, our main goal is to study an outline of numerical resolution of Transport Equations problems
involving this kind of discontinuous functions. In this project, we will work on implementing a Self-Adaptive Theta Scheme as formulated by Pr. Arbogast, 
in the context of the linear advection equation, that modelizes the linear displacement of a quantity in a simple moving environment:

\begin{align*}
    \partial_t u + a\partial_x u = 0 \text{\space \space ($a$ constant)} \tag{1}
\end{align*}
\vspace{10pt}



\section{Material and Methods}
First of all, we will only study the case of one-dimensional $\mathbb{R+} \times \mathbb{R} \rightarrow \mathbb{R}$ functions, and thus stay on a 1D spatial domain, parted with a constant time step.
All of the code will be written in Python, with the help of libraries such as $numpy$, $pyplot$, or $scipy$.

\subsection{Code}
All the useful functions and classes are stored in the file $SATh\_utilities.py$.
We use 5 classes to represent all the objects needed:
\begin{itemize}
    \item the main class $Problem$ that calls the objects of the other classes.
    \item the class $Mesh$ that contains the methods to create the discretized domain.
    \item the class $Matrices$ that creates the useful matrices for the numerical resolution. The function \emph{Iter\_Mat}
builds the iteration matrix for either the simple Theta Scheme (in this case, it is only called once) or the Self-Adaptive Theta Scheme (in this case, it is called at each time step).
This class also inherits from $Mesh$.
    \item the class $Functions$ that creates the useful functions: the item \emph{init\_sol} contains the initial function (at $t=0$) and the item \emph{exact\_sol} contains the exact solution (at $t=t_{final}$)
    \item the class $SATh\_Solver$ contains all the methods needed for the Self-Adaptive Theta method. It is called by the main class.
\end{itemize}

\subsection{Hyperbolic Equations: The Advection Equation}
Here is the formulation of the advection equation:
\begin{align*}
    \partial_t u + a\partial_x u = 0 \text{\space \space ($a$ constant)} \tag{1}
\end{align*}
The parameter $a$ characterizes the speed and direction of the flux modelized by this equation.
We will work with $a > 0$, meaning that, with the time going on, the flux will go from left to right in our spatial domain.
With $a < 0$ the flux would go from right to left, this would have no consequences on the properties of our numerical solving, but it can simplify the implementation.

We will work with Neumann boundary conditions: the values of the derivatives in time of the solution must be equal to 0:
\begin{align*}
    \partial_t u (a) = 0 = \partial_t u (b)
\end{align*}
Indeed, with this choice we will not be bothered by the behaviour of our solutions on the boundary.
This will allow us to focus on the modelling of the displacement of a perturbation strictly inside the domain. See \textit{fig. 1} for an example of the functions we want to study.
We can see that the interest is the perturbation, and that the behaviour on the boundaries is trivial.\\
We can note that with some other types of functions, we can also work with periodical conditions.

\vspace{10pt}

\subsection{The Theta Scheme for the advection equation}

For now, we will work on a 1D spatial domain of size $N$ in the interval $[a,b]$:\\
Let $u$ be a general function defining a field. We split the field u with values $ x_i \text{,} \hspace{8pt} i \in \{0, 1, 2, \ldots, N\}$
And we will write $u(t,x_i) = u_i^t$ \\
When not explicitly written, the values of $a$ and $b$ are respectively 0 and 1.\\

First, let's define the following operators for the discretisation of partial differentiation 
(note that these are dependant of the direction of the flux $a$, here we have as stated previously $a > 0$):
\begin{align*}
    & d_t u = \frac{u^{n+1} - u^n}{\Delta t} \\
    & d_x u = 
    \begin{cases} 
        \frac{u_{i}^n - u_{i-1}^n}{\Delta x} & \text{for } i \in \{1, 2, \ldots, N\} \\
        0 & \text{if } i = 0 
    \end{cases}
\end{align*}
Note that we have introduced a ghost cell at $i=0$, i.e. at the left of the domain, in order to implement the Neumann condition.
Indeed, we will thus always have $u_0^n = u_0^{n+1}$ and $\partial_t u_0 = 0$ for every $n$.\\
At the right boundary, we do not need to do the same thing, because we have restrained to the case where the flux goes from left to right, so the value in the last cell does not depend of another value at its right.

\vspace{8pt}
We can write the Theta Scheme for the equation $(1)$:
\begin{align*}
    d_t u + a\theta d_x u^{n+1} + a(1-\theta) d_x u^n = 0 \tag{2a}
\end{align*}


This scheme has a rate of convergence of order 2 in time (except for the strictly explicit case $\theta=0$ where it is 1), and order 1 in space.\\
We can see that the parameter $\theta$ defines a balance between implicit and explicit resolution.\\
The notation $(2a)$ represents a system of equations, that we now want to write as matrices: \\

\[
\begin{array}{c}
\displaystyle \frac{u^{n+1} - u^n}{\Delta t} + a\theta d_x u^{n+1} + a(1-\theta) d_x u^n = 0 \\
\Leftrightarrow \\
\displaystyle (Id + \Delta t . a \theta d_x)u^{n+1} = u^n - \Delta t .a(1-\theta)d_x u^n \\
\Leftrightarrow \\

\underbrace{
    \begin{pmatrix}
    & 1 & & (0) &\\
    & -a\theta\Delta t & 1+\theta a \Delta t & & \\
    & & \ddots & \ddots \\
    & (0) & -a\theta\Delta t & 1+\theta a \Delta t \\
    \end{pmatrix}
}_{\text{$A$}}

\underbrace{
    \begin{pmatrix}
    u_0^{n+1}\\
    u_1^{n+1}\\
    \vdots \\
    u_N^{n+1}\\
    \end{pmatrix}
}_{\text{$u^{n+1}$}}
=
\underbrace{
    \begin{pmatrix}
    u_0^n\\
    u_1^n - \Delta t .a(1-\theta)d_x u_1^n\\
    \vdots \\
    u_{N}^n - \Delta t .a(1-\theta)d_x u_{N}^n\\
    \end{pmatrix}
}_{b^n} \tag{2b}
\end{array}
\]
We remember that, for exemple, $d_x u_1 = \frac{u_1^n - u_0^n}{\Delta x}$.\\
$A$ is a square matrix depending of the values $\Delta t$, $a$ and $\theta$ which size is equal to the number of points in the mesh,
and $b^n$ a vector of the same size depending of $\Delta t$, $a$, $\theta$ and the values of $u$ at the previous time step $n$.\\
We use the \textit{csr} format of the $scipy.sparse$ library to store $A$, and we solve this system at each time iteration using the $GMRES$ algorithm function from the same library. 


\subsection{Self-Adaptive Theta Scheme for the advection equation}
We now want to use $\theta$ as a parameter to vary at each time step, in order to provide a kind of adaptation to the displacement of the discontinuous jump.
This is the principle of the Self-Adaptive Theta method. For a time step $n$ and a space cell of index $i$, we will solve:
\begin{align*}
    d_t u + a\theta_i^n d_x u^{n+1} + a(1-\theta_i^n) d_x u^n = 0 \tag{3a}
\end{align*}
In this case, the $\theta$ value can be different for two different space coordinates, or for the same space coordinate but at different time step.\\
Our numerical system changes a little bit. Now we have to take care of the variation of the different $\theta$ values:

\[
\begin{array}{c}
\underbrace{
    \begin{pmatrix}
    & 1 & & (0) &\\
    & -a\theta_1^n \Delta t & 1+\theta_1^n a \Delta t & & \\
    & & \ddots & \ddots \\
    & (0) & -a\theta_N^n\Delta t & 1+\theta_N^n a \Delta t \\
    \end{pmatrix}
}_{\text{$A^n$}}

\underbrace{
    \begin{pmatrix}
    u_0^{n+1}\\
    u_1^{n+1}\\
    \vdots \\
    u_N^{n+1}\\
    \end{pmatrix}
}_{\text{$u^{n+1}$}}
=
\underbrace{
    \begin{pmatrix}
    u_0^n\\
    u_1^n - \Delta t .a(1-\theta_1^n)d_x u_1^n\\
    \vdots \\
    u_{N}^n - \Delta t .a(1-\theta_N^n)d_x u_{N}^n\\
    \end{pmatrix}
}_{b^n} \tag{3b}
\end{array}
\]
We need to update the matrix $A^n$ at each time step, contrary to the standard Theta method.\\
The main challenge of this new method is to find an optimal value for each $\theta$. Pr.Arbogast proposes this choice function:

\begin{align*}
    \theta_i^{n+1} = \begin{cases}
        min(max(\theta_{min}, \frac{\tilde{u}_i^{n+1} - u_i^n}{u_i^{n+1} - u_i^n} ), 1) & \text{if } |u_i^{n+1} - u_i^n| > \epsilon \tag{4} \\
        \theta^* & \text{else} 
    \end{cases}
\end{align*}

We introduce $\theta_{min}$ and $\theta^*$ as new parameters of the numerical method.\\
The value $\tilde{u}_i^{n+1}$ is an interpolation of the numerical solution between two time steps.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{indexmapu.png}
    \caption{Representation of the cells and interpolations}
\end{figure}
In the reference paper, it is suggested to use a \textit{Discontinuity Aware Quadrature} to interpolate, in order to obtain a $\tilde{u}$
that loses the less information possible about the perturbation, and thus get the $\theta$ value the most adapted to the discontinuity.
For reasons of time and complexity, we chose to implement a method that does not require to compute this interpolation (as will be seen later).\\

Now, we notice that, in $(4)$, we need the value $u_i^{n+1}$ in order to compute $\theta_i^{n+1}$,
but in the other way we need $\theta_i^{n+1}$ to compute $u_i^{n+1}$.
Mrs. Thomann suggested to use the following fixed-point iteration method to update the $\theta$ values at each time step:\\
We note $\lambda = \frac{\Delta t}{\Delta x}$, $w_i^{n+1} = u_i^{n+1} - u_i^{n}$ and $v_i^{n+1} = \tilde{u}_i^{n+1} - u_i^{n+1}$.\\
On Pr. Arbogast's paper, a formula is given in order to compute $w_i^{n+1}$ and $v_i^{n+1}$:

\begin{align*}
    w_i^{n+1} + \lambda \theta_i^{n+1} w_i^{n+1} = -\lambda(u_i^n - \theta_{i-1}^{n+1} w_{i-1}^{n+1} - u_{i-1}^{n+1}) \tag{5a}\\
    v_i^{n+1} + \frac{\lambda}{2} (\theta_i^{n+1})^2 w_i^{n+1} = -\frac{\lambda}{2} (u_i^n - (\theta_{i-1}^{n+1})^2 w_{i-1}^{n+1} - u_{i-1}^{n+1}) \tag{5b}
\end{align*}

The fixed point iteration will allow us to compute $\theta_i^{n+1}$ by iterating the following system that converges towards it:
\begin{align*}
    w_i^{(k)} + \lambda \theta_i^{(k-1)} w_i^{(k)} = -\lambda(u_i^n - \theta_{i-1}^{(k)} w_{i-1}^{(k)} - u_{i-1}^{n+1}) \tag{6a}\\
    v_i^{(k)} + \frac{\lambda}{2} (\theta_i^{(k-1)})^2 w_i^{(k)} = -\frac{\lambda}{2} (u_i^n - (\theta_{i-1}^{(k)})^2 w_{i-1}^{(k)} - u_{i-1}^{n+1}) \tag{6b}
\end{align*}

\begin{itemize}
    \item For initialization, we know $u^0$ for all the space coordinates. We start with $\theta_i^0 = \theta^*$ for every $i$. This way, we can compute $u^1$ with the usual method.
    \item At each time step, we know $u^n$ and the previously computed $\theta^n$ values.
We compute $u^{n+1}$, and we apply the following algorithm to find one by one the values $\theta_i^{n+1}$:
    \item We always know $w_0^{n+1} = 0$ because of the boundary condition, and, knowing $w_{i-1}^{n+1}$ we can then compute $(w_i^{n+1})^{(0)}$ with the formula $(6a)$.
    \item Then, we iterate $(6a)$ and $(6b)$ in function of $k$: at each step we have $(w_i^{n+1})^{(k)}$, we apply $(6b)$ to compute the value $(v_i^{n+1})^{(k)}$, and we compute $(\theta_i^{n+1})^{(k)}$ with $(4)$.
    \item We check the convergence. we stop at the step $k$ that verifies $|(w_i^{n+1})^{(k)} - (w_i^{n+1})^{(k-1)}| < \tilde{\epsilon}$ with $\tilde{\epsilon}$ a small positive value. %(we take $1e-6$ in this project).
    \item Now we have the definitive $\theta_i^{n+1}$ and $w_i^{n+1}$, and we can start to compute these values for the space cell $i+1$.
    \item When all the space cells are treated, we can compute the numerical solution for the next time step $u^{n+2}$ using $(3b)$.
\end{itemize}


\section{Results}
We will work with $a = 1$, as a change of the speed of the flux is not interesting yet. The same way, we will always work with a final time of $0.1$\\
Wa want to study  and compare the behaviours of the numerical solutions, especially when the mesh precision changes, and when the CFL condition ($=\frac{a\Delta t}{\Delta x}$) changes.

\subsection*{Theta Scheme}

\subsubsection*{Continuous perturbation - Bell}

First of all, we study the simple Theta Scheme with an usual continuous waveform.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Nx500_cfl1:2_allth.png}
    \caption{Bell shaped function, Nx=500, cfl=0.5, numerical solutions for theta from 0 to 1.}
\end{figure}

Let's plot the same thing but with a less precise spatial mesh. As the solution converges in space, we will see the different curves better with a bigger $\Delta x$:
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Nx100_cfl1:2_allth.png}
    \caption{Bell shaped function, Nx=100, cfl=0.5, numerical solutions for theta from 0 to 1.}
\end{figure}

Now let's see what happens with a bad CFL condition:
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Nx500_cfl5_allth.png}
    \caption{Bell shaped function, Nx=500, cfl=5, numerical solutions for theta from 0.2 to 1.}
\end{figure}
The first theta has been cut because the associated solution gets out of bounds, with values exceeding $10^5$.
We can visualize the errors of the numerical solutions for different settings in these conditions:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{th_converr_thetas+Nx_cfl1:2.png}
    \caption{CFL=0.5, errors relative to exact solution, log scale.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{th_converr_thetas+Nx_cfl5.png}
    \caption{CFL=5, errors relative to exact solution, log scale. The first values of theta have been cut because they are significantly larger.}
\end{figure}
We can see that, as expected, the solution converges in space, as the errors diminish when the mesh becomes more precise.
Moreover, in the case of a good CFL condition, the explicit scheme is the most efficient, but in the case of a bad one, the best schemes are the ones with a $\theta$ value around $0.4$ or $0.5$, thus close to the Crank-Nicholson method.


\subsubsection*{Discontinuous perturbation - Jump}
We study the behaviour of theta Scheme solutions for a discontinuous function:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Nx500_cfl1:2_allth_discont.png}
    \caption{Discontinuous function, Nx=500, cfl=0.5, numerical solutions for theta from 0 to 1.}
\end{figure}
The standard Theta Scheme is very bad at preserving the discontinuous shape of our function.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Nx500_cfl5_allth_discont.png}
    \caption{Discontinuous function, Nx=500, cfl=5, numerical solutions for theta from 0.4 to 1}
\end{figure}
With a bad CFL condition, it is worse, and the most explicit schemes trigger the apparition of oscillations. For $\theta$ values lower than $0.4$, the oscillations explode.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{th_converr_thetas+Nx_cfl1:2_discont.png}
    \caption{CFL=0.2, errors relative to exact solution, log scale.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{th_converr_thetas+Nx_cfl5_discont.png}
    \caption{CFL=5, errors relative to exact solution, log scale. The first values of theta have been cut because they are significantly larger.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{th_converr_thetas+Nx_cfl5_discont_allthetas.png}
    \caption{CFL=5, errors relative to exact solution, log scale. We plot all the values of theta for the biggest two meshes.}
\end{figure}
Even if a lot of oscillations appear, we have the same tendancies than for the continuous function:
the most explicit schemes are better for the good CFL condition, and the ones closer the Crank-Nicholson are better for the bad CFL condition.\\

\subsection*{Self-Adaptive Theta Scheme}
As the Fixed-point iteration method is not optimal in terms of computation time, we will not present simulations with meshes of more than $Nx=500$, as they are exponentially slow.\\

Let's start with computing the numerical solutions with $\theta^* = 1$ and $\theta_min = 1$.
because of the choice function $(4)$, this is equivalent to a standard Theta Scheme with $\theta = 1$.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{sath_into_implicit_comparisonbelljump.png}
    \caption{Both shapes with $\theta^* = 1$ and $\theta_min = 1$. The green curve is the numerical solution.}
\end{figure}
We have indeed the same behaviour than in the previous parts (see figures 3 and 8).\\

Now let's study the behaviour for different cases of $\theta^*$ and $\theta_min$:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{sath_thminvary_bell.png}
    \caption{Bell function, Nx=500, CFL+0.5, $\theta_st=0.5$}
\end{figure}
The results are offset with a good CFL.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{sath_thminvary_jump_CFL5.png}
    \caption{Bell function, Nx=500, CFL=5, $\theta_st=0.5$}
\end{figure}
The results are dissipated, but with a less important offset with a  bad CFL.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{sath_thstvary_bell.png}
    \caption{Bell function, Nx=500, $\theta_min=0.5$}
\end{figure}
The variation of $\theta_st$ has an influence on the direction of the leaning of the curve. it is coherent, as it affects the weights of the right and left cell in the scheme.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{sath_thminvary_jump.png}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{sath_thminvary_bell_CFL5.png}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{sath_thstvary_jump.png}
\end{figure}

The results are quite the same for the discontinuous function, with the particularity that the offset seems more impactful.\\
Lets plot some errors:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{jump_thminvary_CFL1:2.png}
    \caption{varying $\theta_min$, CFL=0.5}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{jump_thminvary_CFL5.png}
    \caption{varying $\theta_min$, CFL=5}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{jump_thstvary_CFL1:2.png}
    \caption{varying $\theta^*$, CFL=0.5}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{jump_thstvary_CFL5.png}
    \caption{varying $\theta^*$, CFL=5}
\end{figure}

\section{Conclusion and Discussion}
In conclusion, this version of the Self-Adaptive Theta Scheme is not really efficient. The errors are similar or worse than the simple Theta Scheme for every configuration, except sometimes when the CFL is bad with discontinuous functions.
We can nonetheless note that the scheme is able to adapt to some extent to the discontinuity, so the future is not so dark.\\
The actual Fixed-point iteration method seems not to work, and its computation times are really big. I have checked many times the implementation, but maybe some errors have not been spotted.\\
In the future, we suggest to try a Newton method to find the adapted Thetas. We also suggest to implement a method better using the Discontinuity Aware Quadrature, as we need our scheme to be more fit to the discontinuity.

\section{Bibliography}

\begin{itemize}
    \item Arbogast, Presentation support: \textit{Self Adaptive Theta (SATh) Schemes for Solving Hyperbolic Conservation Laws}, 2024
    \item Arbogast and Huang, \textit{A Self-Adaptive Theta Scheme using discontinuity aware quadrature for solving conservation laws}, 2021.
    \item Boonkkamp and Anthonissen, \textit{The Finite Volume - Complete flux scheme for Advection-Diffusion-Reaction Equations}, 2011
    \item Berzins and Furzeland, \textit{An adaptive theta method for the solution of stiff and nonstiff differential equations}, 1992
\end{itemize}

\begin{align*}
    \theta_i^{n+1} = \begin{cases}
        min(max(\theta_{min}, \frac{\tilde{u}_i^{n+1} - u_i^n}{u_i^{n+1} - u_i^n} ), 1) & \text{if } |u_i^{n+1} - u_i^n| > \epsilon \tag{4} \\
        \theta^* & \text{else} 
    \end{cases}
\end{align*}

\end{document}